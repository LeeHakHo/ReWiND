# @package _global_

defaults:
  - _self_

logging:
  eval_freq: 0
  video_freq: 0

general_training:
  algo: iql
  name: iql
  action_noise: 0.0 # sigma
  learning_rate: 3e-4

  n_critics: 5
  n_critics_to_sample: 2
  
  # IQL-specific parameters
  policy_extraction: 'awr' # awr or ddpg
  awr_advantage_temp: 5.0 # iql only
  ddpg_bc_weight: 0. # iql only
  learning_starts: 5


  action_chunk_size: 60

model:
  policy_layer_norm: true
  critic_layer_norm: true
  pi_net_arch: [1024, 768, 512]
  qf_net_arch: [1024, 1024, 512]

offline_training:
  offline_training_steps: 10000
  ckpt_path: null  # Path to load checkpoint from, if provided will skip offline training
  critic_update_ratio: 1 

online_training:
  total_time_steps: 50000
  warm_start_online_rl: true
  learning_starts: 1000
  critic_update_ratio: 4
  mix_buffers_ratio: 0.50
